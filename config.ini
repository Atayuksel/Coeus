[MODEL]
model_type = bilstm
num_epoch = 200
learning_rate = 0.001
error_function = unweighted
output_directory = predictor_output
use_saved_model = true

[INTERFACE]
root_directory = dataset
dataset_source = ready
batch_size = 50
text_selection = part
relation_type = binary
word_tokenizer = NLTK
word_embedding_dir = wiki_word_vector.txt

[EMBEDDINGS]
position_embedding_flag = false
position_embedding_dir = 
position_embedding_size = 20
pos_tag_embedding_flag = false
pos_tag_embedding_dir = 
pos_tag_embedding_size = 20
iob_tag_embedding_flag = false
iob_tag_embedding_dir = 
iob_tag_embedding_size = 20

[BILSTM]
lstm_hidden_unit = 128
lstm_in_hidden_unit = 0

[CNN]
cnn_filter_out = 300
cnn_hidden_unit = 4096


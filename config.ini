[MODEL]
model_type = bilstm
num_epoch = 30
learning_rate = 0.001
error_function = unweighted
output_directory = predictor_output
train_word_embeddings = true
platform = 'gcp'

[INTERFACE]
root_directory = dataset
dataset_source = biocreative
batch_size = 50
text_selection = part
relation_type = binary
word_tokenizer = NLTK
word_embedding_dir = PubMed-shuffle-win-2.txt
under_sampling = true

[EMBEDDINGS]
position_embedding_flag = true
position_embedding_dir = 
position_embedding_size = 20
pos_tag_embedding_flag = true
pos_tag_embedding_dir = 
pos_tag_embedding_size = 10
iob_tag_embedding_flag = false
iob_tag_embedding_dir = 
iob_tag_embedding_size = 20

[BILSTM]
lstm_hidden_unit = 128
lstm_in_hidden_unit = 0

[CNN]
cnn_filter_out = 250
cnn_hidden_unit = 4096